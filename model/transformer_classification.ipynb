{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Initilization"]},{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-26T09:49:20.525996Z","iopub.status.busy":"2024-06-26T09:49:20.524963Z","iopub.status.idle":"2024-06-26T09:49:20.531174Z","shell.execute_reply":"2024-06-26T09:49:20.530291Z","shell.execute_reply.started":"2024-06-26T09:49:20.525963Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_scheduler\n","from torch.utils.data import DataLoader\n","from tqdm.auto import tqdm\n","import torch\n","import time\n","import numpy as np\n","\n","import multiprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T09:49:22.463362Z","iopub.status.busy":"2024-06-26T09:49:22.462721Z","iopub.status.idle":"2024-06-26T09:49:22.491541Z","shell.execute_reply":"2024-06-26T09:49:22.490690Z","shell.execute_reply.started":"2024-06-26T09:49:22.463329Z"},"trusted":true},"outputs":[],"source":["# from huggingface_hub import notebook_login\n","# notebook_login()\n","# #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"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T09:49:30.358673Z","iopub.status.busy":"2024-06-26T09:49:30.357761Z","iopub.status.idle":"2024-06-26T09:49:30.442020Z","shell.execute_reply":"2024-06-26T09:49:30.441119Z","shell.execute_reply.started":"2024-06-26T09:49:30.358627Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","num_cpus = multiprocessing.cpu_count()\n","num_gpus = torch.cuda.device_count()\n","optimal_workers = min(num_cpus, num_gpus*4) if num_gpus else num_cpus - 1\n","print(f'device: {device} CPU count: {num_cpus} GPU count:{num_gpus}  Workers count: {optimal_workers}')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T09:49:31.833271Z","iopub.status.busy":"2024-06-26T09:49:31.832558Z","iopub.status.idle":"2024-06-26T09:49:31.837302Z","shell.execute_reply":"2024-06-26T09:49:31.836371Z","shell.execute_reply.started":"2024-06-26T09:49:31.833237Z"},"trusted":true},"outputs":[],"source":["roberta_name = \"xlm-roberta-base\"\n","bert_name = \"bert-base-multilingual-cased\"\n","pars_name = \"HooshvareLab/bert-base-parsbert-uncased\"\n","model_name = bert_name"]},{"cell_type":"markdown","metadata":{},"source":["# Data"]},{"cell_type":"markdown","metadata":{},"source":["## Data Loading"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T09:49:34.892197Z","iopub.status.busy":"2024-06-26T09:49:34.891323Z","iopub.status.idle":"2024-06-26T09:49:35.267183Z","shell.execute_reply":"2024-06-26T09:49:35.266458Z","shell.execute_reply.started":"2024-06-26T09:49:34.892160Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv('/kaggle/input/taghche/train.csv')\n","val_df = pd.read_csv('/kaggle/input/taghche/val.csv')\n","test_df = pd.read_csv('/kaggle/input/taghche/test.csv')\n","\n","train_dataset = Dataset.from_pandas(train_df)\n","val_dataset = Dataset.from_pandas(val_df)\n","test_dataset = Dataset.from_pandas(test_df)"]},{"cell_type":"markdown","metadata":{},"source":["## Data Tokenization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T09:49:37.049123Z","iopub.status.busy":"2024-06-26T09:49:37.048732Z","iopub.status.idle":"2024-06-26T09:49:40.849644Z","shell.execute_reply":"2024-06-26T09:49:40.848784Z","shell.execute_reply.started":"2024-06-26T09:49:37.049092Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples['text'], padding='max_length', truncation=True)\n","\n","max_length = 511\n","\n","def truncate_and_tokenize(examples):\n","    truncated_texts = []\n","    for text in examples['text']:\n","        if len(text) > max_length:\n","            truncated_text = text[-max_length:]  # Truncate from the beginning\n","        else:\n","            truncated_text = text\n","        truncated_texts.append(truncated_text)\n","    return tokenizer(truncated_texts, padding='max_length', truncation=True, max_length=max_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T09:49:40.851356Z","iopub.status.busy":"2024-06-26T09:49:40.851081Z","iopub.status.idle":"2024-06-26T09:49:53.602551Z","shell.execute_reply":"2024-06-26T09:49:53.601602Z","shell.execute_reply.started":"2024-06-26T09:49:40.851331Z"},"trusted":true},"outputs":[],"source":["train_dataset = train_dataset.map(truncate_and_tokenize, batched=True)\n","val_dataset = val_dataset.map(truncate_and_tokenize, batched=True)\n","test_dataset = test_dataset.map(truncate_and_tokenize, batched=True)\n","\n","train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T09:50:02.790887Z","iopub.status.busy":"2024-06-26T09:50:02.790527Z","iopub.status.idle":"2024-06-26T09:50:02.796650Z","shell.execute_reply":"2024-06-26T09:50:02.795571Z","shell.execute_reply.started":"2024-06-26T09:50:02.790843Z"},"trusted":true},"outputs":[],"source":["def freeze(model, freeze_layer = [1,2,3,4,5,6]):\n","    base_name = 'bert.encoder.layer.'\n","    freeze_name = [base_name+str(layer) for layer in freeze_layer]\n","    for name, param in model.named_parameters():\n","        if name in freeze_name:\n","            param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T09:50:03.832321Z","iopub.status.busy":"2024-06-26T09:50:03.831916Z","iopub.status.idle":"2024-06-26T09:50:16.406523Z","shell.execute_reply":"2024-06-26T09:50:16.405600Z","shell.execute_reply.started":"2024-06-26T09:50:03.832292Z"},"trusted":true},"outputs":[],"source":["model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n","freeze(model)\n","model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"markdown","metadata":{},"source":["## Setup"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T09:50:39.578797Z","iopub.status.busy":"2024-06-26T09:50:39.578449Z","iopub.status.idle":"2024-06-26T09:50:39.583613Z","shell.execute_reply":"2024-06-26T09:50:39.582598Z","shell.execute_reply.started":"2024-06-26T09:50:39.578768Z"},"trusted":true},"outputs":[],"source":["batch_size = 16\n","epochs = 4\n","logging_steps = 100\n","save_steps_perc = 0.25\n","learning_rate = 5e-5"]},{"cell_type":"markdown","metadata":{},"source":["data loading"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T09:50:41.231297Z","iopub.status.busy":"2024-06-26T09:50:41.230671Z","iopub.status.idle":"2024-06-26T09:50:42.251828Z","shell.execute_reply":"2024-06-26T09:50:42.250830Z","shell.execute_reply.started":"2024-06-26T09:50:41.231264Z"},"trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["optimizer and scheduler"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T09:50:43.284920Z","iopub.status.busy":"2024-06-26T09:50:43.284540Z","iopub.status.idle":"2024-06-26T09:50:43.294222Z","shell.execute_reply":"2024-06-26T09:50:43.293180Z","shell.execute_reply.started":"2024-06-26T09:50:43.284891Z"},"trusted":true},"outputs":[],"source":["optimizer = AdamW(model.parameters(), lr=learning_rate)\n","num_training_steps = epochs * len(train_dataloader)\n","lr_scheduler = get_scheduler(\n","    \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T09:50:44.837375Z","iopub.status.busy":"2024-06-26T09:50:44.837007Z","iopub.status.idle":"2024-06-26T09:50:45.290128Z","shell.execute_reply":"2024-06-26T09:50:45.288634Z","shell.execute_reply.started":"2024-06-26T09:50:44.837345Z"},"trusted":true},"outputs":[],"source":["for epoch in range(epochs):\n","    model.train()\n","    progress_bar = tqdm(range(len(train_dataloader)))\n","    total_loss = 0\n","    start_time = time.time()\n","    for step, batch in enumerate(train_dataloader):\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        outputs = model(input_ids = batch['input_ids'], attention_mask = batch['attention_mask'], labels=batch['label'])\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","        loss.backward()\n","\n","        optimizer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n","        progress_bar.update(1)\n","\n","        if step % logging_steps == 0:\n","            elapsed_time = time.time() - start_time\n","            print(f\"Epoch {epoch + 1}, Step {step}, Loss: {total_loss / (step + 1)}, Time elapsed: {elapsed_time}s\")\n","\n","        # Save model at checkpoints\n","#         if step % int(save_steps_perc * len(train_dataloader)) == 0 and step > 0:\n","#             model.save_pretrained(f'checkpoint-epoch{epoch+1}-step{step}')\n","\n","    # Save model after each epoch\n","    model.save_pretrained(f'model-epoch{epoch+1}')\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0\n","    correct_predictions = 0\n","    total_predictions = 0\n","    with torch.no_grad():\n","        for batch in val_dataloader:\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","            outputs = model(input_ids = batch['input_ids'], attention_mask = batch['attention_mask'], labels=batch['label'])\n","            loss = outputs.loss\n","            val_loss += loss.item()\n","            predictions = outputs.logits.argmax(dim=-1)\n","            correct_predictions += (predictions == batch['label']).sum().item()\n","            total_predictions += predictions.size(0)\n","    val_accuracy = correct_predictions / total_predictions\n","    print(f\"Validation Loss: {val_loss / len(val_dataloader)}, Validation Accuracy: {val_accuracy}\")\n","\n","# Save final model\n","model.save_pretrained('final_model')"]},{"cell_type":"markdown","metadata":{},"source":["# Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T09:36:37.247728Z","iopub.status.busy":"2024-06-26T09:36:37.247135Z","iopub.status.idle":"2024-06-26T09:36:37.597010Z","shell.execute_reply":"2024-06-26T09:36:37.595814Z","shell.execute_reply.started":"2024-06-26T09:36:37.247699Z"},"trusted":true},"outputs":[],"source":["model.eval()\n","test_loss = 0\n","correct_predictions = 0\n","total_predictions = 0\n","with torch.no_grad():\n","    for batch in test_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        with torch.cuda.amp.autocast():\n","            outputs = model(input_ids = batch['input_ids'], attention_mask = batch['attention_mask'], labels=batch['label'])\n","            loss = outputs.loss\n","            test_loss += loss.item()\n","            predictions = outputs.logits.argmax(dim=-1)\n","            correct_predictions += (predictions == batch['label']).sum().item()\n","            total_predictions += predictions.size(0)\n","test_accuracy = correct_predictions / total_predictions\n","print(f\"Test Loss: {test_loss / len(test_dataloader)}, Test Accuracy: {test_accuracy}\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5284733,"sourceId":8790112,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
