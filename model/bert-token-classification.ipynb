{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8923027,"sourceType":"datasetVersion","datasetId":5332759}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install necessary libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport time\n","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:06:00.946706Z","iopub.execute_input":"2024-07-10T16:06:00.947061Z","iopub.status.idle":"2024-07-10T16:06:19.465488Z","shell.execute_reply.started":"2024-07-10T16:06:00.947036Z","shell.execute_reply":"2024-07-10T16:06:19.464688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()\n# #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","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:06:19.467149Z","iopub.execute_input":"2024-07-10T16:06:19.467684Z","iopub.status.idle":"2024-07-10T16:06:19.496479Z","shell.execute_reply.started":"2024-07-10T16:06:19.467658Z","shell.execute_reply":"2024-07-10T16:06:19.495568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the model to GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:06:19.497623Z","iopub.execute_input":"2024-07-10T16:06:19.497899Z","iopub.status.idle":"2024-07-10T16:06:19.556410Z","shell.execute_reply.started":"2024-07-10T16:06:19.497876Z","shell.execute_reply":"2024-07-10T16:06:19.555563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load and preprocess the data","metadata":{}},{"cell_type":"markdown","source":"## Load txt file and create dataframe","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/persian-ner/BIO_train_df.csv\")\nval_df = pd.read_csv(\"/kaggle/input/persian-ner/BIO_val_df.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/persian-ner/BIO_test_df.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:06:19.558623Z","iopub.execute_input":"2024-07-10T16:06:19.558935Z","iopub.status.idle":"2024-07-10T16:06:19.708427Z","shell.execute_reply.started":"2024-07-10T16:06:19.558890Z","shell.execute_reply":"2024-07-10T16:06:19.707691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[train_df['tag'] == 'B-org', 'tag'] = 'B-ORG'\ntrain_df.loc[train_df['tag'] == 'I-org', 'tag'] = 'I-ORG'\nval_df.loc[val_df['tag'] == 'B-org', 'tag'] = 'B-ORG'\nval_df.loc[val_df['tag'] == 'I-org', 'tag'] = 'I-ORG'\ntest_df.loc[test_df['tag'] == 'B-org', 'tag'] = 'B-ORG'\ntest_df.loc[test_df['tag'] == 'I-org', 'tag'] = 'I-ORG'\nunique_tags = train_df['tag'].unique()\nprint(unique_tags)\ntrain_df = train_df[[\"token\", \"tag\"]]\nval_df = val_df[[\"token\", \"tag\"]]\ntest_df = test_df[[\"token\", \"tag\"]]\ntrain_df.head(10)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:06:19.709401Z","iopub.execute_input":"2024-07-10T16:06:19.709663Z","iopub.status.idle":"2024-07-10T16:06:19.806094Z","shell.execute_reply.started":"2024-07-10T16:06:19.709641Z","shell.execute_reply":"2024-07-10T16:06:19.805233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define NER tags and Custom dataset","metadata":{}},{"cell_type":"markdown","source":"# Set up the model for fine-tuning","metadata":{}},{"cell_type":"code","source":"# Map tags to integers\ntag2id = {tag: index for index, tag in enumerate(unique_tags)}\nid2tag =  {value: key for key, value in tag2id.items()}\n\n# Custom dataset class\nclass NERDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, tag2id, max_len=128):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.tag2id = tag2id\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        token = self.data.iloc[idx, 0].split()  # Token is split into a list of strings\n        tag = self.data.iloc[idx, 1].split()  # Tag is split into a list of strings\n\n        encoding = self.tokenizer(\n            token,\n            is_split_into_words=True,\n            return_offsets_mapping=True,\n            padding='max_length',\n            truncation=True,\n            max_length=self.max_len\n        )\n        tags = [self.tag2id.get(t) for t in tag]\n\n        input_ids = encoding['input_ids']\n        attention_mask = encoding['attention_mask']\n        offset_mapping = encoding['offset_mapping']\n        \n        # Create a new tags list that matches the length of the input_ids\n        new_tags = []\n        tags_idx = 0\n        for i, offset in enumerate(offset_mapping):\n            if offset[0] == 0 and offset[1] != 0:  # Only consider non-padding tokens\n                if tags_idx < len(tags):\n                    new_tags.append(tags[tags_idx])\n                    tags_idx += 1\n                else:\n                    new_tags.append(self.tag2id['O'])\n            else:\n                new_tags.append(-100)  # Use -100 to ignore these tokens in the loss calculation\n        \n        item = {key: torch.tensor(val) for key, val in encoding.items()}\n        item['labels'] = torch.tensor(new_tags)\n        return item","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:06:19.807131Z","iopub.execute_input":"2024-07-10T16:06:19.807385Z","iopub.status.idle":"2024-07-10T16:06:19.818593Z","shell.execute_reply.started":"2024-07-10T16:06:19.807362Z","shell.execute_reply":"2024-07-10T16:06:19.817758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def freeze(model, freeze_layer = [1,2,3,4,5,6]):\n#     base_name = 'bert.encoder.layer.'\n#     freeze_name = [base_name+str(layer) for layer in freeze_layer]\n#     for name, param in model.named_parameters():\n#         if name in freeze_name:\n#             param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:06:19.819670Z","iopub.execute_input":"2024-07-10T16:06:19.819965Z","iopub.status.idle":"2024-07-10T16:06:19.830918Z","shell.execute_reply.started":"2024-07-10T16:06:19.819942Z","shell.execute_reply":"2024-07-10T16:06:19.830059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load tokenizer and model\npars_bert  = \"HooshvareLab/bert-base-parsbert-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(pars_bert)\nmodel = AutoModelForTokenClassification.from_pretrained(pars_bert, num_labels=len(tag2id))\n# freeze(model)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:06:19.831877Z","iopub.execute_input":"2024-07-10T16:06:19.832126Z","iopub.status.idle":"2024-07-10T16:06:25.934862Z","shell.execute_reply.started":"2024-07-10T16:06:19.832104Z","shell.execute_reply":"2024-07-10T16:06:25.933973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 128\nBATCH_SIZE = 32\nEPOCHS = 2\nLEARNING_RATE = 3e-5\nlogging_steps = 100\n","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:06:25.936108Z","iopub.execute_input":"2024-07-10T16:06:25.936462Z","iopub.status.idle":"2024-07-10T16:06:25.941130Z","shell.execute_reply.started":"2024-07-10T16:06:25.936429Z","shell.execute_reply":"2024-07-10T16:06:25.940252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create dataset","metadata":{}},{"cell_type":"code","source":"# Create datasets\ntrain_dataset = NERDataset(train_df, tokenizer, tag2id)\nval_dataset = NERDataset(val_df, tokenizer, tag2id)\ntest_dataset = NERDataset(test_df, tokenizer, tag2id)\n\n# Data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:06:25.943849Z","iopub.execute_input":"2024-07-10T16:06:25.944111Z","iopub.status.idle":"2024-07-10T16:06:25.951981Z","shell.execute_reply.started":"2024-07-10T16:06:25.944089Z","shell.execute_reply":"2024-07-10T16:06:25.951160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom training loop","metadata":{}},{"cell_type":"markdown","source":"## Define optimizer and scheduler\n","metadata":{}},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\ntotal_steps = len(train_loader) * EPOCHS\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:06:25.952938Z","iopub.execute_input":"2024-07-10T16:06:25.953175Z","iopub.status.idle":"2024-07-10T16:06:25.966992Z","shell.execute_reply.started":"2024-07-10T16:06:25.953154Z","shell.execute_reply":"2024-07-10T16:06:25.966016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"huggingface code","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:06:25.968121Z","iopub.execute_input":"2024-07-10T16:06:25.968416Z","iopub.status.idle":"2024-07-10T16:06:25.972746Z","shell.execute_reply.started":"2024-07-10T16:06:25.968382Z","shell.execute_reply":"2024-07-10T16:06:25.971903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Chat-Gpt code","metadata":{}},{"cell_type":"code","source":"model.eval()\ntest_loss = 0\ncorrect_predictions = 0\ntotal_predictions = 0\nstep =0 \nwith torch.no_grad():\n    \n    for batch in tqdm(test_loader):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        with torch.cuda.amp.autocast():\n            outputs = model(input_ids =  batch['input_ids'], attention_mask = batch['attention_mask'],\n                            token_type_ids = batch['token_type_ids'], # offset_mapping=batch['offset_mapping'],\n                            labels =  batch['labels'])\n            loss = outputs.loss\n            test_loss += loss.item()\n            predictions = outputs.logits.argmax(dim=-1)\n            correct_predictions += (predictions == batch['labels']).sum().item()\n            total_predictions += predictions.size(0)\ntest_accuracy = correct_predictions / total_predictions\nprint(f\"Test Loss: {test_loss / len(test_loader)}, Test Accuracy: {test_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-10T15:06:46.970990Z","iopub.execute_input":"2024-07-10T15:06:46.971784Z","iopub.status.idle":"2024-07-10T15:07:20.367374Z","shell.execute_reply.started":"2024-07-10T15:06:46.971732Z","shell.execute_reply":"2024-07-10T15:07:20.366364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    model.train()\n    total_loss = 0\n    start_time = time.time()\n    for step, batch in tqdm(enumerate(train_loader),total=len(train_loader)):\n\n        batch = {k: v.to(device) for k, v in batch.items()}\n        \n        outputs = model(input_ids =  batch['input_ids'], attention_mask = batch['attention_mask'],\n                            token_type_ids = batch['token_type_ids'], # offset_mapping=batch['offset_mapping'],\n                            labels =  batch['labels'])\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n\n        if step % logging_steps == 0:\n            elapsed_time = time.time() - start_time\n            print(f\"Epoch {epoch + 1}, Step {step}, Loss: {total_loss / (step + 1)}, Time elapsed: {elapsed_time}s\")\n\n        # Save model at checkpoints\n#         if step % int(save_steps_perc * len(train_dataloader)) == 0 and step > 0:\n#             model.save_pretrained(f'checkpoint-epoch{epoch+1}-step{step}')\n\n    # Save model after each epoch\n#     model.save_pretrained(f'model-epoch{epoch+1}')\n\n    # Validation\n    model.eval()\n    val_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(input_ids =  batch['input_ids'], attention_mask = batch['attention_mask'],\n                            token_type_ids = batch['token_type_ids'], # offset_mapping=batch['offset_mapping'],\n                            labels =  batch['labels'])\n            loss = outputs.loss\n            val_loss += loss.item()\n            predictions = outputs.logits.argmax(dim=-1)\n            correct_predictions += (predictions == batch['labels']).sum().item()\n            total_predictions += predictions.size(0)\n    val_accuracy = correct_predictions / total_predictions\n    print(f\"Validation Loss: {val_loss / len(val_loader)}, Validation Accuracy: {val_accuracy}\")\n# Save final model\nmodel.save_pretrained('final_model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the model","metadata":{}},{"cell_type":"code","source":"model.eval()\ntest_loss = 0\ncorrect_predictions = 0\ntotal_predictions = 0\n\n# Initialize lists to store true labels and predictions\nprediction_list = []\nground_truth = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        with torch.cuda.amp.autocast():\n            outputs = model(\n                input_ids=batch['input_ids'], \n                attention_mask=batch['attention_mask'],\n                token_type_ids=batch['token_type_ids'], \n                labels=batch['labels']\n            )\n            loss = outputs.loss\n            test_loss += loss.item()\n            predictions = outputs.logits.argmax(dim=-1)\n            \n            correct_predictions += (predictions == batch['labels']).sum().item()\n            total_predictions += predictions.size(0)\n            \n            # Collect true labels and predictions\n            prediction_list.append(predictions[:,1])\n            ground_truth.append(batch['labels'][:,1])\n\ntest_accuracy = correct_predictions / total_predictions\naverage_test_loss = test_loss / len(test_loader)\nprint(f\"Test Loss: {average_test_loss}, Test Accuracy: {test_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:09:09.051251Z","iopub.execute_input":"2024-07-10T16:09:09.051596Z","iopub.status.idle":"2024-07-10T16:09:42.631915Z","shell.execute_reply.started":"2024-07-10T16:09:09.051569Z","shell.execute_reply":"2024-07-10T16:09:42.630981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Custom compute metrics function\ndef compute_metrics(true_labels, pred_labels):\n    metrics = {\n        'f1': f1_score(true_labels, pred_labels, average='macro'),\n        'accuracy': accuracy_score(true_labels, pred_labels),\n        'precision': precision_score(true_labels, pred_labels, average='macro'),\n        'recall': recall_score(true_labels, pred_labels, average='macro'),\n        'confusion_matrix': confusion_matrix(true_labels, pred_labels)\n    }\n\n    return metrics","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:09:42.633535Z","iopub.execute_input":"2024-07-10T16:09:42.633841Z","iopub.status.idle":"2024-07-10T16:09:42.639373Z","shell.execute_reply.started":"2024-07-10T16:09:42.633816Z","shell.execute_reply":"2024-07-10T16:09:42.638517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = compute_metrics(np.concatenate([tensor.flatten().cpu() for tensor in ground_truth]),\n                          np.concatenate([tensor.flatten().cpu() for tensor in prediction_list])\n                         )\n\n# Print the computed metrics\nprint(f\"F1 Score: {metrics['f1']}\")\nprint(f\"Accuracy: {metrics['accuracy']}\")\nprint(f\"Precision: {metrics['precision']}\")\nprint(f\"Recall: {metrics['recall']}\")\nprint(f\"Confusion Matrix:\\n{metrics['confusion_matrix']}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-10T16:09:42.640323Z","iopub.execute_input":"2024-07-10T16:09:42.640602Z","iopub.status.idle":"2024-07-10T16:09:42.737755Z","shell.execute_reply.started":"2024-07-10T16:09:42.640561Z","shell.execute_reply":"2024-07-10T16:09:42.736981Z"},"trusted":true},"execution_count":null,"outputs":[]}]}