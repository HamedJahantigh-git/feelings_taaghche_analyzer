{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "<center> درس پردازش زبان‌های طبیعی </center>\n",
    "<center> تمرین سری سوم </center>\n",
    "<center> تشخیص احساس نظرات طاقچه </center>\n",
    "<center> ترم بهار 1403-1402 </center>\n",
    "</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style='direction:rtl;'>\n",
    "    شماره گروه: 18\n",
    "</h4>\n",
    "<div style='direction:rtl;'>\n",
    "    <b>اعضای تیم:<br></b>\n",
    "    امیر شکوری (402206437)<br>   \n",
    "    زهرا ملکی (402206183)<br>\n",
    "    حامد جهانتیغ (401212324)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style='direction:rtl;'>\n",
    "    # معرفی\n",
    "</h2>\n",
    "<div style=\"direction: rtl;\">\n",
    "در این تمرین تحلیل احساس نظرات طاقچه مد نظر می باشد. تمرین در دو دسته اصلی طبقه بندی متن و طبقه بندی کلمه انجام شده است. به طور کلی سه بخش اصلی گزارش به شرح زیر می باشد:\n",
    "<ol>\n",
    "  <li>آماده سازی داده ها</li>\n",
    "  <li>طبقه بندی سند</li>\n",
    "  <li>طبقه بندی کلمه</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    "برای عدم وجود مشکل در اجرا، تمامی کتابخانه های استفاده شده در فایل <i>requirements.txt</i> قرار گرفته است که در اینجا فرآیند نصب انجام می شود. همچنین کتابخانه های مورد استفاده در فایل نوت بوک گزارش هر کدام در بخش مورد نیاز خود فراخوانی می شود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.path import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style='direction:rtl;'>\n",
    "    # آماده سازی داده ها\n",
    "</h2>\n",
    "<div style=\"direction: rtl;\">\n",
    "در این بخش، تلاش شده تا داده ها متناسب با تسک های تعریف شده آماده شوند و عملیات پیش پردازش و تکمیل داده ها انجام شود. برای تحقق این امر روند زیر طی شده است:\n",
    "<ol>\n",
    "<li>تکمیل داده ها با استخراج اطلاعات تکمیلی نویسندگان، مترجمان و انتشارات</li>\n",
    "<li>تحلیل داده ها برای متناسب سازی 5 سطح از رتبه بندی(تعیین هایپرپارامتر)</li>\n",
    "<li>تمیزسازی اولیه داده های نظرات متناسب با تسک های تعریف شده</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='direction:rtl;'>\n",
    "    ## تکمیل داده ها با استخراج اطلاعات تکمیلی نویسندگان، مترجمان و انتشارات\n",
    "</h3>\n",
    "<div style=\"direction: rtl;\">\n",
    "برای تکمیل داده ها، از یک کرالر پایتون استفاده شده است که پیاده سازی آن در پکیج <i>data</i> فایل <i>data_processor.py</i> قرار دارد.\n",
    "\n",
    "todo amir\n",
    "\n",
    "\n",
    "همین طور نحوه ایجاد فایل BIO از ترکیب ner1 و آرش\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='direction:rtl;'>\n",
    "    ##تحلیل داده ها برای متناسب سازی 5 سطح از رتبه بندی(تعیین هایپرپارامتر)\n",
    "</h3>\n",
    "<div style=\"direction: rtl;\">\n",
    "برای تعیین هایپر پارامتر حالت های مختلفی وجود دارد، باتوجه به توزیع داده ها و سیاق جملات در 4 حالت مرزها بررسی می شود. روند بررسی بدین صورت است که در هر حالت مدل ParsBert براساس داده های دسته بندی حالات مختلف آموزش داده می شود. تنطیمات برای انجام این فرآیند به شرح زیر است:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 1\n",
    "logging_steps = 100\n",
    "save_steps_perc = 0.25\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    "درنهایت نتایج برای حالات به شرح زیر اقدام می شود:\n",
    "<li>مثبت: 4-5، خنثی: 2-3، منفی: 0-1 -> 72.0% با داده بالانس 10074 </li>\n",
    "<li>مثبت: 5، خنثی: 2-4، منفی: 0-1 -> 72.6% با داده بالانس 10074 </li>\n",
    "<li>مثبت: 5، خنثی: 3-4، منفی: 0-2 -> 69.7% با داده بالانس 13868 </li>\n",
    "<li>مثبت: 5، خنثی: 4، منفی: 0-3 -> 68.7% با داده بالانس 9356 </li>\n",
    "در نتیجه دسته بندی حالت دوم عملکرد بهتری را ایجاد می کند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='direction:rtl;'>\n",
    "    ## تمیزسازی اولیه داده های نظرات متناسب با تسک های تعریف شده\n",
    "</h3>\n",
    "<div style=\"direction: rtl;\">\n",
    "todo amir\n",
    "این بخش درمورد stop words ها هم ذکر بشه. چیزهایی هم که برای تمیز کردن داده ها اوردیم بیاد امیرجان\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style='direction:rtl;'>\n",
    "    # طبقه بندی سند\n",
    "</h2>\n",
    "<div style=\"direction: rtl;\">\n",
    "همان طور که در این فعالیت مشخص شده است، هدف تعیین دسته نظر نرم افزار طاقچه در یکی از دسته های مثبت، منفی و خنثی می باشد. برای انجام این فعالیت از دو مدل پایه و اصلی استفاده شده است که هرکدام در این بخش شرح داده می شود. همچنین برای این فعالیت لازم است تا برخی موارد از جمله تعیین هایپرپارامتر مرزی نظر، انتخاب کلمات بی اثر در احساس نظرات انجام شود که در بخش آماده سازی داده ها انجام شده است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='direction:rtl;'>\n",
    "    ## مدل پایه\n",
    "</h3>\n",
    "<div style=\"direction: rtl;\">\n",
    "todo amir\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='direction:rtl;'>\n",
    "    ## مدل اصلی\n",
    "</h3>\n",
    "<div style=\"direction: rtl;\">\n",
    "در این بخش برای تحلیل احساسات از یک مدل برپایه ترنسفورمر استفاده می شود. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    " <b>1- گام اول:</b>\n",
    "  </br>\n",
    " اولین قدمی که برای تعیین مدل برداشته شده است، انتخاب مدل است. در این مرحله از دو کاندید برای خانوادی BERT استفاده  و بر روی یک دیتای پایه ای ثابت آموزش انجام شد تا بتوان این دو مدل را مقایسه کرد. هر دو مدل بر اساس دفترچه transformer_classification.ipynb آموزش داده میشوند و از سری مدل های موجود در Huggingface هستند. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_name = \"bert-base-multilingual-cased\"\n",
    "pars_name = \"HooshvareLab/bert-base-parsbert-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    "در نهایت مدل اول (مدل پایه ای BERT برای کاربردهای چندزبانه) دارای دقت کمتری از مدل توسعه پیدا کرده برای زبان فارسی برپایه BERT (با نام ParsBERT) می باشد. این دقت برای داده آموزشی مبنا به ترتیب برابر 64% و  81% می باشد. بنابراین مدل انتخابی ParsBERT خواهد بود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    " <b>2- گام دوم:</b>\n",
    "</br>\n",
    "در گام دوم، استراتژی آموزش مشخص می شود. با توجه به حجم اطلاعات موجود، یکی از مواردی که باعث بهبود دقت مدل می شود، ثابت نگاه داشتن ضرایت لایه های پایین که دارای دانش کلی زبان هستند و فاین تیون کردن لایه های بالایی متناسب با داده های فعالیت می باشد. در همین راستا مدل برگزیده (ParsBERT) در چهار سناریو زیر مورد ارزیابی قرار میگیرد:\n",
    "<li>بدون انجماد لایه ها و فاین تیون کردن کل شبکه</li>\n",
    "<li> انجماد لایه های 1-3 و فاین تیون لایه های بالاتر</li>\n",
    "<li> انجماد لایه های 1-6 و فاین تیون لایه های بالاتر</li>\n",
    "<li> انجماد لایه های 1-9 و فاین تیون لایه های بالاتر</li>\n",
    "در نهایت دقت برای نمونه داده آموزش برای هر سناریو به ترتیب 81.1%، 80.7%، 80.4% و 80.9% می باشد. هممچنین زمان آموزش شبکه برای همه سناریوها در یک مرتبه قرار دارد.\n",
    "به همین علت در این بخش تفاوتی در انتخاب سناریو یافت نشد. لازم به ذکر است در پیاده سازی این سناریوها در مدل پایه ای BERT تفاوت ایجاد شده ملموس است؛ به عنوان مثال دقت در حالت بدون انجماد از 64% به 75% در حالت انجماد لایه های 1-6 می رسد. احتمالا در مدل ParsBERT براساس فاین تیون شدن اختصاصی برای زبان فارسی این تفاوت در سناریو دیگر وجود ندارد.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    " <b>3- گام سوم:</b>\n",
    "</br> \n",
    "در این مرحله متناسب با سناریو انتخابی و هایپر پارامتر تعیین شده، مدل آموزش داده می شود. تنظیمات کلی مدل به شرح زیر است:\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 5\n",
    "logging_steps = 100\n",
    "save_steps_perc = 0.25\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    " <b>نتایج و دقت مدل</b>\n",
    "</br> \n",
    "در نهایت دقت مدل بر روی تقریبا 30 هزار داده با نسبت 8،1،1 به  داده های آموزش، اعتبارسنجی و آزمون به شرح زیر است:\n",
    "<li>F1 Score: 0.799</li>\n",
    "<li>Accuracy: 0.800</li>\n",
    "<li>Precision: 0.801</li>\n",
    "<li>Recall: 0.800</li>\n",
    "<li>\n",
    "Confusion Matrix:\n",
    "[[831 128  90]\n",
    " [ 82 756 116]\n",
    " [ 57 131 832]]\n",
    "</li>\n",
    "در نهایت مدل در نشانی زیر در Huggingface بارگزاری گردید.\n",
    "\n",
    "https://huggingface.co/hamedjahantigh/TaaghcheFeelingCommentAnalysis\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style='direction:rtl;'>\n",
    "    # طبقه بندی کلمات\n",
    "</h2>\n",
    "<div style=\"direction: rtl;\">\n",
    "همان طور که در این فعالیت مشخص شده است، هدف ایجاد تگ BIO می باشد.\n",
    " برای انجام این فعالیت از دو مدل پایه و اصلی استفاده شده است که هرکدام در این بخش شرح داده می شود. همچنین برای این فعالیت لازم است تا داده های آن تکمیل و آماده شود که در بخش اول به آن پرداخته شده است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 style='direction:rtl;'>\n",
    "# مدل پایه\n",
    "</h3>\n",
    "<div style=\"direction: rtl;\">\n",
    "Todo kahnom maleki\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 style='direction:rtl;'>\n",
    "# مدل اصلی\n",
    "</h3>\n",
    "<div style=\"direction: rtl;\">\n",
    "در این بخش برای ایجاد یک تگ BIO از یک مدل برپایه ترنسفورمر و مدل ParsBERT استفاده می شود. تگ های استفاده شده در این بخش \n",
    "['O' 'B-DAT' 'I-DAT' 'B-PER' 'I-PER' 'B-ORG' 'I-ORG' 'B-LOC' 'I-LOC'\n",
    " 'B-EVE' 'I-EVE' 'B-BOOK' 'I-BOOK']\n",
    " می باشد. همچنین تنظیمات اولیه مدل در پایین آورده شده است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 3e-5\n",
    "logging_steps = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    " <b>نتایج و دقت مدل</b>\n",
    "</br> \n",
    "در نهایت دقت مدل بر روی تقریبا 150 هزار کلمه با نسبت 8،1،1 به داده های آموزش، اعتبارسنجی و آزمون به شرح زیر است:\n",
    "<li>F1 Score: </li>\n",
    "<li>Accuracy: </li>\n",
    "<li>Precision: </li>\n",
    "<li>Recall: </li>\n",
    "<li>\n",
    "Confusion Matrix:\n",
    "[[831 128  90]\n",
    " [ 82 756 116]\n",
    " [ 57 131 832]]\n",
    "</li>\n",
    "در نهایت مدل در نشانی زیر در Huggingface بارگزاری گردید.\n",
    "\n",
    "https://huggingface.co/hamedjahantigh/TaaghcheBIOTag\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## مدل HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ۱. بارگذاری و آماده‌سازی داده‌ها:\n",
    "- دو فایل متنی شامل جملات آموزش و تست از دو منبع مختلف بارگذاری شدند.\n",
    "- داده‌ها به صورت جملات توکن‌بندی شده و برچسب‌گذاری شده استخراج شدند.\n",
    "- جملات آموزشی به صورت دستی متوقف شدند تا از طولانی شدن بیش از حد فرآیند جلوگیری شود.\n",
    "\n",
    "### ۲. پردازش داده‌ها:\n",
    "- جملات و برچسب‌ها به صورت جداگانه برای مجموعه‌های آموزش و تست ذخیره شدند.\n",
    "- توکن‌ها و برچسب‌ها از جملات استخراج و به لیست‌های جداگانه‌ای تبدیل شدند.\n",
    "\n",
    "### ۳. برچسب‌گذاری و کدگذاری:\n",
    "- توکن‌ها و برچسب‌ها با استفاده از LabelEncoder از کتابخانه sklearn کدگذاری شدند.\n",
    "- جملات توکن‌بندی شده به فرمت قابل استفاده برای HMM تبدیل شدند.\n",
    "\n",
    "### ۴. ساخت و آموزش مدل:\n",
    "- یک مدل HMM با استفاده از کتابخانه hmmlearn ساخته و با داده‌های آموزشی آموزش داده شد.\n",
    "- مدل نهایی ذخیره شد تا در آینده مورد استفاده قرار گیرد.\n",
    "\n",
    "### ۵. ارزیابی مدل:\n",
    "- داده‌های تست با استفاده از مدل پیش‌بینی شدند.\n",
    "- دقت، F1-score، Precision و Recall برای مدل محاسبه و گزارش شدند.\n",
    "- ماتریس درهم‌ریختگی (Confusion Matrix) برای تحلیل عملکرد مدل ترسیم شد.\n",
    "\n",
    "### نتایج:\n",
    "- مدل توانست دقت، F1-score، Precision و Recall مناسبی را برای شناسایی موجودیت‌های نام‌دار ارائه دهد.\n",
    "- ماتریس درهم‌ریختگی نشان‌دهنده‌ی عملکرد مدل در پیش‌بینی صحیح برچسب‌ها بود.\n",
    "\n",
    "### ارزیابی مدل\n",
    "- پس از آماده‌سازی داده‌ها و آموزش مدل، با استفاده از داده‌های تست، عملکرد مدل ارزیابی شد.\n",
    "- مقادیر مختلف از جمله دقت، F1-score، Precision و Recall محاسبه و گزارش شدند.\n",
    "- همچنین، ماتریس درهم‌ریختگی به صورت گرافیکی ترسیم شد تا عملکرد مدل به صورت بصری بررسی شود.\n",
    "\n",
    "### نتایج نهایی:\n",
    "- Accuracy: 58.74%\n",
    "- F1-macro score: 5.37%\n",
    "- F1-micro score: 58.73%\n",
    "- Precision-macro: 5.94%\n",
    "- Precision-micro: 58.73%\n",
    "- Recall-macro: 5.94%\n",
    "- Recall-micro: 58.73%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
