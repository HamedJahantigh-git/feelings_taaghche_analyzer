{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "<center> درس پردازش زبان‌های طبیعی </center>\n",
    "<center> تمرین سری سوم </center>\n",
    "<center> تشخیص احساس نظرات طاقچه </center>\n",
    "<center> ترم بهار 1403-1402 </center>\n",
    "</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style='direction:rtl;'>\n",
    "    شماره گروه: 18\n",
    "</h4>\n",
    "<div style='direction:rtl;'>\n",
    "    <b>اعضای تیم:<br></b>\n",
    "    امیر شکوهی (402206437)<br>   \n",
    "    زهرا ملکی (402206183)<br>\n",
    "    حامد جهانتیغ (401212324)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style='direction:rtl;'>\n",
    "    # معرفی\n",
    "</h2>\n",
    "<div style=\"direction: rtl;\">\n",
    "\n",
    "<ol>\n",
    "  <li>آماده سازی داده ها</li>\n",
    "  \n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    "برای عدم وجود مشکل در اجرا، تمامی کتابخانه های استفاده شده در فایل <i>requirements.txt</i> قرار گرفته است که در اینجا فرآیند نصب انجام می شود. همچنین کتابخانه های مورد استفاده در فایل نوت بوک گزارش هر کدام در بخش مورد نیاز خود فراخوانی می شود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 4))\n",
      "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting torch (from -r requirements.txt (line 5))\n",
      "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (4.12.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (4.66.4)\n",
      "Requirement already satisfied: typing in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (3.7.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 1)) (2024.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn->-r requirements.txt (line 4))\n",
      "  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m211.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 4))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->-r requirements.txt (line 4))\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from torch->-r requirements.txt (line 5))\n",
      "  Downloading filelock-3.15.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (4.12.2)\n",
      "Collecting sympy (from torch->-r requirements.txt (line 5))\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch->-r requirements.txt (line 5))\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch->-r requirements.txt (line 5))\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch->-r requirements.txt (line 5))\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.3.1 (from torch->-r requirements.txt (line 5))\n",
      "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->-r requirements.txt (line 7)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->-r requirements.txt (line 7)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->-r requirements.txt (line 7)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->-r requirements.txt (line 7)) (2024.6.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.10/site-packages (from beautifulsoup4->-r requirements.txt (line 8)) (2.5)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->-r requirements.txt (line 5))\n",
      "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch->-r requirements.txt (line 5))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m762.5/779.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m00:06\u001b[0mm\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 466, in read\n",
      "    s = self.fp.read(amt)\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.10/ssl.py\", line 1303, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.10/ssl.py\", line 1159, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_internal/cli/req_command.py\", line 245, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_internal/commands/install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_internal/operations/prepare.py\", line 552, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_internal/operations/prepare.py\", line 467, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_internal/network/download.py\", line 183, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/hamed_sistan/University/Course/NLP/feelings_taaghche_analyzer/.venv/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.path import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style='direction:rtl;'>\n",
    "    # آماده سازی داده ها\n",
    "</h2>\n",
    "<div style=\"direction: rtl;\">\n",
    "در این بخش، تلاش شده تا داده ها متناسب با تسک های تعریف شده آماده شوند و عملیات پیش پردازش و تکمیل داده ها انجام شود. برای تحقق این امر روند زیر طی شده است:\n",
    "<ol>\n",
    "<li>تکمیل داده ها با استخراج اطلاعات تکمیلی نویسندگان، مترجمان و انتشارات</li>\n",
    "<li>تحلیل داده ها برای متناسب سازی 5 سطح از رتبه بندی</li>\n",
    "<li>تمیزسازی اولیه داده های نظرات متناسب با تسک های تعریف شده</li>\n",
    "<li>بخش بندی داده ها</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='direction:rtl;'>\n",
    "    ## تکمیل داده ها با استخراج اطلاعات تکمیلی نویسندگان، مترجمان و انتشارات\n",
    "</h3>\n",
    "<div style=\"direction: rtl;\">\n",
    "برای تکمیل داده ها، از یک کرالر پایتون استفاده شده است که پیاده سازی آن در پکیج <i>data</i> فایل <i>data_processor.py</i> قرار دارد.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
